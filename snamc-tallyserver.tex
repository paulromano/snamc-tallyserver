\documentclass{snamc2013}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}  % allows inclusion of graphics
\usepackage{booktabs}  % nice rules (thick lines) for tables
\usepackage{microtype} % improves typography for PDF

\usepackage[breaklinks=true, linkcolor=black, citecolor=black]{hyperref}
\hypersetup{colorlinks=true,
  pdftitle={On the use of tally servers in Monte Carlo simulations of light-water
  reactors},
  pdfauthor={Paul K. Romano, Benoit Forget, and Kord Smith}}

% Add \unit macro
\newcommand{\unit}[1]{\ensuremath{\, \mathrm{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{On the use of tally servers in Monte Carlo simulations of light-water
  reactors}

\author{Paul K. Romano}
\author{Benoit Forget}
\author{Kord Smith}

\affil{Massachusetts Institute of Technology, Department of Nuclear Science and
  Engineering, 77 Massachusetts Avenue, Cambridge, MA 02139}

\abstract{An algorithm for decomposing tally data using servers has recently
  been proposed and analyzed. In the present work, we investigate the impact of
  subdividing fuel into annular segments on several parameters of a theoretical
  model that predicts the overhead from using tally servers. The full paper will
  also discuss the impact of survival biasing and weight cutoffs on these
  parameters, the use of non-blocking communication in the tally server
  implementation in OpenMC, and tests of the tally server algorithm using tens
  to hundreds of thousands of processors.}

\keywords{Monte Carlo, data decomposition, tally server, LWR, OpenMC}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Typical parallel implementations of Monte Carlo particle transport rely on full
replication of the problem data on each process. This approach has been shown to
be highly scalable~\cite{ane-romano-2013}, but does not lend itself to problems
where the memory requirements exceed that of a single node such as the analysis
of light-water reactors where tally data can exceed terabytes. Two methods of
decomposing data and thereby reducing per-node memory requirements have been
proposed previously: \emph{domain decomposition}~\cite{jcp-siegel-2012-1,
  jcp-siegel-2012-2} and \emph{data decomposition}.

In a recent paper~\cite{jcp-romano-2013}, Romano et al. demonstrate an
implementation of data decomposition via a tally server algorithm and show that
it offers a viable means of performing full core light-water reactor simulations
via Monte Carlo. A theoretical model was developed to predict the performance of
a simulation using the tally server algorithm relative to a simulation based on
full memory replication. The model depends on a number of machine-, code-, and
problem-dependent parameters. For the sake of simplicity, some of the
assumptions made in estimating these parameters were not conservative. In the
present work, we revisit the assumptions made in~~\cite{jcp-romano-2013} to
develop more realistic parameters for use in the theoretical model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tally Server Model}

In the previous work by Romano et al.~\cite{jcp-romano-2013}, it was shown that
the relative increase in total simulation time due to using tally servers for
decomposing tally memory is
\begin{equation}
  \label{eq:delta}
  \Delta = \frac{f}{\mu} \left ( \alpha + d\beta \right )
\end{equation}
where $\Delta$ is the overhead, $f$ is the number of scoring events per
particle, $\mu$ is the average time to simulate a particle, $\alpha$ is the
network latency, $d$ is the size of the tally scores per event, and $\beta$ is
the inverse network bandwidth. The latency and inverse bandwidth are determined
by the network interconnect; $f$, $\mu$, and $d$ will depend on the machine
hardware as well as the code being used and the model being simulated.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parameter Sensitivity}

The previous test cases~\cite{jcp-romano-2013} were targeted at depletion
analysis of the Monte Carlo performance benchmark~\cite{mc2011-hoogenboom} on
two modern supercomputers: the Titan Cray XK7 at ORNL and Intrepid Blue Gene/P
at ANL. In a depletion simulation, six reaction rates for each nuclide must be
tallied each time a particle track crosses fuel. Furthermore, it is necessary to
subdivide fuel regions into annular segments since spatial self-shielding will
result in the outer part of a fuel pin depleting faster than the inner part. The
impact of this subdivision of the fuel on $f$ and $\mu$ was not previously
accounted for. With an increasing number of subdivisions, the number of events
that will result in contributions to tallies will increase. At the same time,
the time to simulate a single particle will increase since there will be more
surface crossings, re-evaluation of cross sections, tallying events, etc.

To explicitly determine the effect of fuel subdivision on $f$ and $\mu$, a
series of simulations were run using the OpenMC Monte Carlo
code~\cite{ane-romano-2013} on a detailed full core PWR benchmark
model~\cite{mc2013-horelik} varying the number of annular regions in the fuel
from 1 to 10. The benchmark model includes accurate enrichment loadings,
burnable absorber patterns, and control bank positions as well as
faithfully-modeled axial grid spacers, core baffle structures, neutron shield
panel structures, and relevant core internals. \autoref{fig:events} shows the
dependence of $f$ on the number of annular regions. While not intuitively
obvious, this figure demonstrates that the number of tracks is directly
proportional to the number of annular regions.
\begin{figure}[htb]
  \centering
  \includegraphics[width=3.0in]{events}
  \caption{Number of tracks in fuel as a function of the number of fuel ring
    segments.}
  \label{fig:events}
\end{figure}

In OpenMC, each time a particle enters a new material, the macroscopic cross
sections must be calculated. This is true even if the particle hasn't changed
energy. Thus, as the number of annular segments in fuel increases, the
calculation time will increase due predominantly to the extra cross section
evaluations. \autoref{fig:time} shows the dependence of $\mu$ on the number of
annular regions.
\begin{figure}[b]
  \centering
  \includegraphics[width=3.0in]{time}
  \caption{Relative simulation time per particle as a function of the number of
    fuel ring segments.}
  \label{fig:time}
\end{figure}

We see that $f$ is directly proportional to the number of annular regions,
whereas $\mu$ increases only slightly. Thus, the tally server overhead based on
\eqref{eq:delta} will increase almost in direct proportion to the number of
annular regions. \autoref{fig:model} shows the predicted overhead on the Titan
supercomputer as a function of $d$ for varying numbers of annular regions based
on the results in \autoref{fig:events} and \autoref{fig:time}. The upper limit
on $d$ is 15,360 bytes, the amount of tally data for six reaction rates in each
of 320 nuclides within a material. We have used a latency of $\alpha = 2.0 \cdot
10^{-6} \unit{s}$ and an inverse bandwidth of $\beta = 2.5 \cdot 10^{-10}
\unit{s/byte}$. The particle tracking rate with one region in the fuel is $1/\mu
= 140 \unit{particle/s}$.
\begin{figure}[htb]
  \centering
  \includegraphics[width=3.3in]{model}
  \caption{Estimated tally server overhead on the Titan Cray XK7 supercomputer
    as a function of the number of fuel ring segments.}
  \label{fig:model}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

In this paper, we have demonstrated the effect of fuel subdivision on the number
of particle tracks and calculation rate on a PWR benchmark problem using the
OpenMC Monte Carlo code. In the context of using a tally server data
decomposition algorithm, it was shown that the overhead due to tally servers
will increase linearly with the number of annular regions in fuel. Nevertheless,
even with 10 regions, the predicted overhead of using tally servers is less than
20\% on the Titan supercomputer over a wide parameter regime.

The full paper will also discuss the impact of survival biasing and weight
cutoffs on $f$ and $\mu$, the use of non-blocking communication in the tally
server implementation in OpenMC, and tests of the tally server algorithm using
tens to hundreds of thousands of processors.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}

This research was performed under appointment of the first author to the
Rickover Fellowship Program in Nuclear Engineering sponsored by Naval Reactors
Division of the U.S. Department of Energy. This work was also supported in part
by the Office of Advanced Scientific Computing Research, Office of Science,
U.S. Department of Energy, under Contract DE-AC02-06CH11357.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ans}
\bibliography{references}
\end{document}
